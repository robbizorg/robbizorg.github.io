[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Robin Netzorg",
    "section": "",
    "text": "A girl close to noise.\nI’m Robin Netzorg (she/her), a fifth-year PhD student in UC Berkeley’s EECS Department, advised by Prof. Gopala Anumanchipalli and Prof. Bin Yu. Research-wise, I’m currently interested in flexible speech synthesis and voice modification, with a particular interest in applying these techniques to build tools for speech therapy and Gender-Affirming Voice Training (GAVT). Previously, I was interested in interpretable machine learning and causal inference, but, well, sometimes you just have to make a drastic life change in the fourth year of your PhD.\nOutside of research, I’m your semi-stereotypical Bay Area trans girl. I’m into making “music” with my friends, playing video games, reading books, and jotting down thoughts in my journal. Check out my research below or click here to see whatever it is I’ve decided to post."
  },
  {
    "objectID": "index.html#selected-research",
    "href": "index.html#selected-research",
    "title": "Robin Netzorg",
    "section": "Selected Research",
    "text": "Selected Research\n\n\n\n\n  \n\n\n\n\nPerMod: Perceptually Grounded Voice Modification with Latent Diffusion Models\n\n\n\n\n\n\n\n\n\n\n\n\nDec 16, 2023\n\n\nRobin Netzorg, Ajil Jalal, Luna McNulty, Gopala Anumanchipalli\n\n\n\n\n\n\n  \n\n\n\n\nTowards an Interpretable Representation of Speaker Identity via Perceptual Voice Qualities\n\n\n\n\n\n\n\n\n\n\n\n\nOct 4, 2023\n\n\nRobin Netzorg, Bohan Yu, Andrea Guzman, Peter Wu, Luna McNulty, Gopala Anumanchipalli\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "papers/permod/index.html#abstract",
    "href": "papers/permod/index.html#abstract",
    "title": "PerMod: Perceptually Grounded Voice Modification with Latent Diffusion Models",
    "section": "Abstract",
    "text": "Abstract\nPerceptual modification of voice is an elusive goal. While non-experts can modify an image or sentence perceptually with available tools, it is not clear how to similarly modify speech along perceptual axes. Voice conversion does make it possible to convert one voice to another, but these modifications are handled by black box models, and the specifics of what perceptual qualities to modify how to modify them are unclear. Towards allowing greater perceptual control over voice, we introduce PerMod, a conditional latent diffusion model that takes in an input voice and a perceptual qualities vector, and produces a voice with the matching perceptual qualities. Unlike prior work, PerMod generates a new voice corresponding to perceptual modifications. Evaluating perceptual quality vectors with RMSE from both human and predicted labels, we demonstrate that PerMod produces voices with the desired perceptual qualities for typical voices, but performs poorly on atypical voices."
  },
  {
    "objectID": "posts/hello_again/index.html",
    "href": "posts/hello_again/index.html",
    "title": "Finally Made a Website. Aka, Welcome to My Life",
    "section": "",
    "text": "A girl who has her shit life together\nAfter years and years, and years, and years and years and years, I made a website. The first time I ever talked about wanting to make a website was approximately on December 28, 2017. So that’s, what, since my junior year of college I’ve been thinking and failing to make a website? Let’s code out how long it’s been, cause why not:\nCode\nfrom datetime import datetime\n\n# Start and end dates\nstart_date = datetime(2017, 12, 28)\nend_date = datetime(2023, 11, 4)\n\n# Get that difference\ndifference = end_date - start_date\n\n# Conversionssss\nyears = difference.days // 365\nmonths = (difference.days % 365) // 30\ndays = (difference.days % 365) % 30\n\nprint(f\"Beep boop beep: It took you {years} years, {months} months, and {days} days to make me! Beep boop beep.\")\n\n\nBeep boop beep: It took you 5 years, 10 months, and 12 days to make me! Beep boop beep.\nJesus H. Christ. It took me almost six years to actually get around to building this thing! If you asked college junior me how I’d feel knowing that it would take me six years to put together a simple website, I’d probably have responded with initial disbelief at future girl-me, horrendous confusion as to why the first thing she’d bring up is a stupid website, and then a impending sense of dread at my own inability to be able to stick to the things that I “needed” to do.\nMight be obvious by the fact that it took me six years to get around to it, but, as it turns out, a personal website isn’t necessary to your career or personal development at all. Even as an unsuccessful PhD student, a personal website didn’t really matter much. Arguably, it’s probably a better thing not to have one. The self-importance, the stupifying effect of marketing, people learning what I actually think. Shudder. Not good things.\nBut here I am six years later, having made a personal website. Why? I could pontificate for paragraphs about the need to market oneself in today’s economy in order to maximize the impact and visibility of one’s work, but I’ll spare you the details. Just know, a big part of this is probably because I feel like I actually have work to share now, that it’s important that people see this work, and that’s why I’m making this.\nThere’s this article I’ve been wanting to write for years, “To Share or Not to Share”. Well, I used to want to write it. back when I still thought I was neurotypical enough to be able to handle more than one task at a time, to be able to take the time to craft out a well-reasoned and researched argument while being a “full-time” grad student. So easy to beat yourself up over that stuff.\nAnyways! The gist of the article is simple, and getting it out in some form is better than not it all, so here’s the grand question I felt like I had to share with the world around me: In this hyperactive, distracted, terminally online age, if I don’t share my life, do I exist? I know I got so much stuff going on that I sometimes forget about people until I see their content pop up somewhere. How true is that for others? Do people only think of me when a picture I post pops up on their feed? If I spend all my time alone, not sharing and posting my life and thoughts, am I even real?\n(A bit selfish, don’t you think?)\nIn a former life, I studied popularity on Twitch, and what we found in the course of our non-causal study was clear. Popularity is a combination of hard work and blind luck. Research! Betting on blind luck seems like a losing strategy, so may as well lean into whatever this hard work thing is. We couldn’t really measure content quality, but it was pretty clear that the people who grew in popularity the most were very active content creators.\nIt makes sense, you’re not going to get people to pay attention to you unless you’re something that can be perceived in the first place. And on Twitch, the way to do that is stream. On pretty much any social media website, the way to do that is post. In real life, at least here in the US, where we probably don’t live close to the people we care about, where we probably won’t run into friends in our day-to-day routines unless it’s planned, where the addictive allure and perceived safety of anonymity online compels us to lie indoors in catatonic depression, how do you be perceivable?\nIt’s simple. You share.\nIt really doesn’t matter what you share, or how you share it. As long as a little notification pops up that has your name attached to it, that person had to think of you for that brief moment. For that moment, you existed outside of that little head of yours. If you do it enough, maybe they start developing a need for that notification, craving it every time they open their phone. Maybe they dread it. Maybe there’s an app keeping count, reminding that that if they don’t think of you, they’re going to lose all some kind of streak. Maybe they can’t wait to think of you, so they find a community of people who just think about you. Then you could look yourself up on Google and confirm what you hoped to be true all along:\nUgh, the Internet sucks so much.\nThis is obviously just a tad bit insane, but there’s definitely some kernel of truth to it. The nagging thought over the yeras of making a website probably came from some version of this need to exist outside of my own head. All this before I needed people to affirm my identity as a woman. Do you know how much I want people to perceive me for who I know myself to be? That little existential validation when a friend calls me pretty–how could I resist sharing a pic or two?\nAt the same time, is your online-self actually you? Are you representing yourself how you want to be represented? Are people perceiving you the way you want to be perceived? I feel like it’s so easy to lose yourself by obsessing over these questions, not to mention the real chance of harm from that people can inflict on one another…\nTo share or not to share, that is the question."
  },
  {
    "objectID": "posts/hello_again/index.html#the-sunday-sophist",
    "href": "posts/hello_again/index.html#the-sunday-sophist",
    "title": "Finally Made a Website. Aka, Welcome to My Life",
    "section": "The Sunday Sophist",
    "text": "The Sunday Sophist\nYears ago, back when I thought I was neurotypical enough to handle more than one task at a time, I dreamt of releasing semi-regular essays on my random musings. Turns out, I didn’t have the time, energy, or dedication to do it, but maybe I can do a not semi-regular posting of trivial thoughts?\nWhen I was back in college, I somehow ended up in the position of being a teaching assistant for a graduate-level class. Masters students were going to some 19 year old kid for advice on their AI home. Imposter syndrome was real (is it ever not?), and I thought of myself as a bit of a sophist–literally a teacher these people were paying who had less life and educational experience than them.\nAcademics, with our air of legitimacy, citation counts, and wasted years, have a tendency to overinflate the importance of the thoughts we have, or their validity. We build off of prior work, point to the textbook, and use sound, reasonable logic to make our claims. We are to be believed, we say. You can trust us. We, after all, are the experts.\nI was hoping that at some point I’d feel less like an imposter, some kind of sophist. Eventually, with enough experience and affirmation, I’d develop my own sense of security in my knowledge. If I read enough, write enough, and think enough, I’d finally be confident in what I believe and my ability to teach it. I’d be a real expert. Eventually, I’d finally have something worth saying!\nThrough the years, and I mean years, that feeling of security has never come. In times when my career was going well (which has it ever gone well?), to times when my career was not going well, I’ve never felt secure in what I’m doing or what I know. So many people are wrong, regardless of their sound logic and mountains of references, how would I know if I’m ever right?\nI don’t, and that’s okay. To be honest, I don’t think I ever want to know if I’m right or not. That sort of certainty sounds scary. Besides, the rush of fear when someone points out a flaw in my reasoning is way more exciting. That uncertainty in it of itself is reassuring. I trust myself to change my opinion when I’m wrong, to always doubt myself just enough to not take myself too seriously, to be kind of happy with being a sophist. Who’s really real, anyways?\n\nWelcome to my website. Based on the available readership statistics, the vast majority of you never make it down this far anyways. But if you did, thank you, I guess? I’ve been dreading making a website, but, at this point in my career, I feel like I have to. Maybe I’ll expand on that at some point. Maybe I won’t. Who knows? I suffer from the unfortunate affliction of wanting to write for the sake of writing, even if I have nothing to say. I’ll probably ramble more unsubstantiated claims about a variety of topics over the time to come. And if you’re wondering why I would ever share these thoughts in my head, let met tell you this: I’m sharing them because I want to. Where that want comes from, I don’t know. Are they worth sharing, and am I someone who’s worth listening to? Probably not.\nWho’s worth listening to anyways?"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Tutorials, Demos, and Random, Random Musings",
    "section": "",
    "text": "Finally Made a Website. Aka, Welcome to My Life\n\n\n\n\n\n\n\nblog\n\n\n\n\n\n\n\n\n\n\n\nNov 4, 2023\n\n\nRobbie\n\n\n\n\n\n\n  \n\n\n\n\nVoice Research #1: Exploring the Perceptual Voice Qualities Database with Pandas and Seaborn\n\n\n\n\n\n\n\nperceptual qualities\n\n\nvoice research\n\n\n\n\n\n\n\n\n\n\n\nNov 4, 2023\n\n\nRobin\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "papers/pq_rep/index.html#abstract",
    "href": "papers/pq_rep/index.html#abstract",
    "title": "Towards an Interpretable Representation of Speaker Identity via Perceptual Voice Qualities",
    "section": "Abstract",
    "text": "Abstract\nUnlike other data modalities such as text and vision, speech does not lend itself to easy interpretation. While lay people can understand how to describe an image or sentence via perception, non-expert descriptions of speech often end at high-level demographic information, such as gender or age. In this paper, we propose a possible interpretable representation of speaker identity based on perceptual voice qualities (PQs). By adding gendered PQs to the pathology-focused Consensus Auditory-Perceptual Evaluation of Voice (CAPE-V) protocol, our PQ-based approach provides a perceptual latent space of the character of adult voices that is an intermediary of abstraction between high-level demographics and low-level acoustic, physical, or learned representations. Contrary to prior belief, we demonstrate that these PQs are hearable by ensembles of non-experts, and further demonstrate that the information encoded in a PQ-based representation is predictable by various speech representations."
  },
  {
    "objectID": "posts/explore_pvqd/index.html",
    "href": "posts/explore_pvqd/index.html",
    "title": "Voice Research #1: Exploring the Perceptual Voice Qualities Database with Pandas and Seaborn",
    "section": "",
    "text": "Another day, another tutorial\n\n\nWelcome to a blog post about exploring the Perceptual Voice Qualities Database (PVQD). This is based off of a ML + Speech workshop I held in the Berkeley Speech Group in Fall ’23. That workshop and the workbooks are available online if you want to work with the code yourself! If you’re interested in Deep Learning, there’s also some cool stuff in there about working with HuBERT representations of speech data too! The workshop doesn’t assume any knowledge of Pandas, Machine Learning, or Deep Learning, with the focus is more on getting your hands dirty with the tools vs. understanding 100% of what you’re doing.\nThat said, if you want to learn more about the tools, the repo contains a list of resources for learning more.\nAnyways, if I’m linking to that repo, you might be wondering, why write a blog post about it? First, who doesn’t love a bit of redundancy? Second, not everyone is going to want to actually work with the code themselves. I want to communicate and share the stuff I’ve been working on, and generally share the thought processes I have when trying to work with Speech data. This is to get feedback on my work from folks who might not know a lot about data science and machine learning. This is also to serve as a type of onboarding and explanation tool for those interested in conducting voice research with publicly available datasets. Finally, I really, really need just say what I do in plain english!\n\n\n\n\n\n\n\n\n\n\n\nIf you’re interested in studying how voice varies across demographics and vocal health, the PVQD is a great starting point. Not only does the dataset contain ~2hrs of audio from vastly different speakers, the data also comes with demographic information about the speakers as well. Let’s visualize that now.\n\n\nCode\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nplt.rcdefaults() # Default\n\ndemo_df = pd.read_csv(\"../../data/pvqd/pvqd_demographics.csv\")\ndemo_df.head(5)\n\n\n\n\n\n\n\n\n\nParticipant ID\nGender\nAge\nDiagnosis\n\n\n\n\n0\nBL01\nM\n46\nNaN\n\n\n1\nBL02\nF\n76\nNaN\n\n\n2\nBL03\nF\n88\nNaN\n\n\n3\nBL04\nF\n42\nNaN\n\n\n4\nBL05\nF\n75\nNaN\n\n\n\n\n\n\n\nWe see that the PVQD comes with three pieces of demographic information: the participants’ Gender, Age, Diagnosis. Frustratingly as someone interested in studying transgender and gender-diverse voices, there aren’t that many datasets out there that contain more inclusive labels of gender. Gender, in the vast majority of datasets, is listed as a binary “F” or “M”. In addition to binary labels of gender, from my personal experience, most of publicly available speech datasets do not contain non-cisgender speakers. For the construction of machine learning models that can provide feedback on gender affirming voice training, this is a huge limitation. Machine learning methods often fail to generalize to unseen data, especially when that data is “out of distribution”.\nAlthough we won’t be able to get a complete map of what voice is capable of, we can start to get a rough one. The nice thing about the PVQD is that it does provide us with voices that do exhibit certain qualities we might want to avoid during voice training, such as breathiness and strain. Let’s load in that data while we’re talking about it:\n\n\nCode\npq_train = pd.read_csv(\"../../data/pvqd/train_test_split/y_train.csv\", index_col=0)\npq_train.head(5)\n\n\n\n\n\n\n\n\n\nFile\nBreathiness\nLoudness\nPitch\nRoughness\nStrain\n\n\n\n\n0\nLA7005\n7.000000\n7.333333\n7.000000\n8.500000\n8.000000\n\n\n1\nPT116\n31.833333\n12.333333\n6.000000\n29.500000\n7.333333\n\n\n2\nPT034\n43.166667\n26.666667\n61.166667\n34.000000\n30.333333\n\n\n3\nSJ6006\n4.375000\n5.125000\n0.250000\n3.750000\n6.875000\n\n\n4\nPT005\n5.500000\n7.000000\n12.000000\n3.833333\n4.500000\n\n\n\n\n\n\n\nAs we said before, the CAPE-V measures perceptual qualities on a 1-100 scale. Since these values are the average of six different raitngs, we get all those decimal places. It’s nice to look at the data like that, to make sure it’s there, but we’re still a bit away from actually learning anything about the data. I’m brushing this part under the rug (see the workshop if you’re curious!), but I’m going to clean up the data and combine the two dataframes so we can start drawing some connections.\n\n\nCode\n### Fix up the demo_df first\n\n## Fix Gender\ncor_gender = {\n    \"f\": \"F\",\n    \"m\": \"M\",\n    \"female\": \"F\",\n    \"male\": \"M\"\n}\n\ndemo_df[\"Gender\"] = demo_df[\"Gender\"].str.lower().map(cor_gender)\n\n## Make Binary Value for Diagnosis\n# Create a function to apply to the column\ndef process_diagnosis(diagnosis):\n    if pd.isnull(diagnosis):\n        return np.nan\n    if diagnosis == \"N\":\n        return \"N\"\n    else:\n        return \"Y\"\n\ndemo_df[\"Diagnosis \"] = demo_df[\"Diagnosis \"].map(process_diagnosis)\n\n## We can't visualize nan data, so let's not consider those rows\n# ~ is a way to invert a numpy array/pandas series of boolean values. A handy trick\ndiagnosis_df = demo_df[~pd.isnull(demo_df[\"Diagnosis \"])]\n\n# Rename column and remote white space\ndiagnosis_df = diagnosis_df.rename(columns={\"Participant ID \": \"File\"})\ndiagnosis_df[\"File\"] = diagnosis_df[\"File\"].str.upper().str.strip()\n\n## Combine the Data\n\n# Merge the two dataframes using a left join\nmatched_df = pq_train.merge(diagnosis_df, how=\"left\", on=\"File\")\n\nmatched_df = matched_df[~pd.isnull(matched_df[\"Gender\"])]\n\nprint(\"Number of NaN Values: %s\" % len(matched_df[pd.isnull(matched_df[\"Gender\"])]))\n\nmatched_df.head()\n\n\nNumber of NaN Values: 0\n\n\n\n\n\n\n\n\n\nFile\nBreathiness\nLoudness\nPitch\nRoughness\nStrain\nGender\nAge\nDiagnosis\n\n\n\n\n0\nLA7005\n7.000000\n7.333333\n7.000000\n8.500000\n8.000000\nF\n52.0\nY\n\n\n1\nPT116\n31.833333\n12.333333\n6.000000\n29.500000\n7.333333\nF\n81.0\nY\n\n\n2\nPT034\n43.166667\n26.666667\n61.166667\n34.000000\n30.333333\nF\n80.0\nY\n\n\n3\nSJ6006\n4.375000\n5.125000\n0.250000\n3.750000\n6.875000\nF\n17.0\nN\n\n\n4\nPT005\n5.500000\n7.000000\n12.000000\n3.833333\n4.500000\nF\n58.0\nY\n\n\n\n\n\n\n\nCool! We have our combined dataset that has all the information in one place.\n\n\n\nLet’s start doing our explorations! The first thing we should figure out is what the age and gender makeup of the dataset looks like.\n\n\nCode\ngender_breakdown = diagnosis_df[[\"Gender\", \"Age\"]].groupby(\"Gender\").agg([\"mean\", \"count\"]).reset_index()\n\nsns.histplot(data=diagnosis_df, x=\"Age\", hue=\"Gender\")\nplt.show()\n\ngender_breakdown\n\n\n\n\n\n\n\n\n\n\n\n\nGender\nAge\n\n\n\n\nmean\ncount\n\n\n\n\n0\nF\n43.861878\n181\n\n\n1\nM\n50.020833\n96\n\n\n\n\n\n\n\nSeems like there’s about twice as many women in the dataset than men, with many of the women being younger on average.\nWhat about the age and diagnosis breakdown?\n\n\nCode\nsns.histplot(data=diagnosis_df, x=\"Age\", hue=\"Diagnosis \")\nplt.show()\n\n\n\n\n\nWhile there are quite a few young people with diagnosis, we see that healthy older individuals are underrepresented in the dataset, and the majority of those with diagnoses skew older.\nFrom this point on, it’s important to note that I’m only dealing with the training set to avoid biasing the results we find. It is okay to compute statistics about the demographics over the entire dataset, but, since we are hoping to build models that learn the perceptual qualities, performing data exploration with them in the data could possibly bias our findings. To make sure we have a proper test set to evaluate our findings on, we’ll conduct our exploration on the training data."
  },
  {
    "objectID": "posts/explore_pvqd/index.html#what-is-the-perceptual-voice-qualities-database",
    "href": "posts/explore_pvqd/index.html#what-is-the-perceptual-voice-qualities-database",
    "title": "Exploring the Perceptual Voice Qualities Database with Pandas and Seaborn",
    "section": "What is the Perceptual Voice Qualities Database?",
    "text": "What is the Perceptual Voice Qualities Database?"
  },
  {
    "objectID": "posts/explore_pvqd/index.html#exploration",
    "href": "posts/explore_pvqd/index.html#exploration",
    "title": "Exploring the Perceptual Voice Qualities Database with Pandas and Seaborn",
    "section": "Exploration!",
    "text": "Exploration!"
  },
  {
    "objectID": "posts/explore_pvqd/index.html#what-is-pandas-and-data-science",
    "href": "posts/explore_pvqd/index.html#what-is-pandas-and-data-science",
    "title": "Exploring the Perceptual Voice Qualities Database with Pandas and Seaborn",
    "section": "What is Pandas and Data Science?",
    "text": "What is Pandas and Data Science?"
  },
  {
    "objectID": "posts/explore_pvqd/index.html#what-is-perceptual-voice-quality",
    "href": "posts/explore_pvqd/index.html#what-is-perceptual-voice-quality",
    "title": "Exploring the Perceptual Voice Qualities Database with Pandas and Seaborn",
    "section": "What is Perceptual Voice Quality?",
    "text": "What is Perceptual Voice Quality?"
  },
  {
    "objectID": "posts/explore_pvqd/index.html#what-is-perceptual-voice-quality-and-the-pvqd",
    "href": "posts/explore_pvqd/index.html#what-is-perceptual-voice-quality-and-the-pvqd",
    "title": "Exploring the Perceptual Voice Qualities Database with Pandas and Seaborn",
    "section": "What is Perceptual Voice Quality and the PVQD?",
    "text": "What is Perceptual Voice Quality and the PVQD?"
  },
  {
    "objectID": "posts/explore_pvqd/index.html#what-sort-of-research-do-you-do",
    "href": "posts/explore_pvqd/index.html#what-sort-of-research-do-you-do",
    "title": "Exploring the Perceptual Voice Qualities Database with Pandas and Seaborn",
    "section": "What Sort of Research Do You Do?",
    "text": "What Sort of Research Do You Do?\nThat’s a question for another blog post."
  },
  {
    "objectID": "posts/explore_pvqd/index.html#what-are-perceptual-voice-qualities-and-the-pvqd",
    "href": "posts/explore_pvqd/index.html#what-are-perceptual-voice-qualities-and-the-pvqd",
    "title": "Voice Research #1: Exploring the Perceptual Voice Qualities Database with Pandas and Seaborn",
    "section": "What are Perceptual Voice Qualities and the PVQD?",
    "text": "What are Perceptual Voice Qualities and the PVQD?"
  },
  {
    "objectID": "posts/explore_pvqd/index.html#what-are-pandas-and-seaborn",
    "href": "posts/explore_pvqd/index.html#what-are-pandas-and-seaborn",
    "title": "Voice Research #1: Exploring the Perceptual Voice Qualities Database with Pandas and Seaborn",
    "section": "What are Pandas and Seaborn?",
    "text": "What are Pandas and Seaborn?"
  },
  {
    "objectID": "posts/explore_pvqd/index.html#lets-do-some-viz",
    "href": "posts/explore_pvqd/index.html#lets-do-some-viz",
    "title": "Voice Research #1: Exploring the Perceptual Voice Qualities Database with Pandas and Seaborn",
    "section": "Let’s Do Some Viz",
    "text": "Let’s Do Some Viz\nIf you’re interested in studying how voice varies across demographics and vocal health, the PVQD is a great starting point. Not only does the dataset contain ~2hrs of audio from vastly different speakers, the data also comes with demographic information about the speakers as well. Let’s visualize that now.\n\n\nCode\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\ndemo_df = pd.read_csv(\"../../data/pvqd/pvqd_demographics.csv\")\ndemo_df.head(5)\n\n\n\n\n\n\n\n\n\nParticipant ID\nGender\nAge\nDiagnosis\n\n\n\n\n0\nBL01\nM\n46.0\nNaN\n\n\n1\nBL02\nF\n76.0\nNaN\n\n\n2\nBL03\nF\n88.0\nNaN\n\n\n3\nBL04\nF\n42.0\nNaN\n\n\n4\nBL05\nF\n75.0\nNaN\n\n\n\n\n\n\n\nWe see that the PVQD comes with three pieces of demographic information: the participants’ Gender, Age, Diagnosis. Frustratingly as someone interested in studying transgender and gender-diverse voices, there aren’t that many datasets out there that contain more inclusive labels of gender. Gender, in the vast majority of datasets, is listed as a binary “F” or “M”. In addition to binary labels of gender, from my personal experience, most of publicly available speech datasets do not contain non-cisgender speakers. For the construction of machine learning models that can provide feedback on gender affirming voice training, this is a huge limitation. Machine learning methods often fail to generalize to unseen data, especially when that data is “out of distribution”.\nAlthough we won’t be able to get a complete map of what voice is capable of, we can start to get a rough one. The nice thing about the PVQD is that it does provide us with voices that do exhibit certain qualities we might want to avoid during voice training, such as breathiness and strain. Let’s load in that data while we’re talking about it:\n\n\nCode\npq_train = pd.read_csv(\"../../data/pvqd/train_test_split/y_train.csv\", index_col=0)\npq_train.head(5)\n\n\n\n\n\n\n\n\n\nFile\nBreathiness\nLoudness\nPitch\nRoughness\nStrain\n\n\n\n\n0\nLA7005\n7.000000\n7.333333\n7.000000\n8.500000\n8.000000\n\n\n1\nPT116\n31.833333\n12.333333\n6.000000\n29.500000\n7.333333\n\n\n2\nPT034\n43.166667\n26.666667\n61.166667\n34.000000\n30.333333\n\n\n3\nSJ6006\n4.375000\n5.125000\n0.250000\n3.750000\n6.875000\n\n\n4\nPT005\n5.500000\n7.000000\n12.000000\n3.833333\n4.500000\n\n\n\n\n\n\n\nAs we said before, the CAPE-V measures perceptual qualities on a 1-100 scale. Since these values are the average of six different raitngs, we get all those decimal places."
  },
  {
    "objectID": "posts/explore_pvqd/index.html#why-use-data-science-and-machine-learning-to-study-voice",
    "href": "posts/explore_pvqd/index.html#why-use-data-science-and-machine-learning-to-study-voice",
    "title": "Voice Research #1: Exploring the Perceptual Voice Qualities Database with Pandas and Seaborn",
    "section": "Why Use Data Science and Machine Learning to Study Voice?",
    "text": "Why Use Data Science and Machine Learning to Study Voice?"
  },
  {
    "objectID": "papers/permod/index.html",
    "href": "papers/permod/index.html",
    "title": "PerMod: Perceptually Grounded Voice Modification with Latent Diffusion Models",
    "section": "",
    "text": "Demo"
  },
  {
    "objectID": "posts/explore_pvqd/index.html#preprocessing-the-pvqd",
    "href": "posts/explore_pvqd/index.html#preprocessing-the-pvqd",
    "title": "Voice Research #1: Exploring the Perceptual Voice Qualities Database with Pandas and Seaborn",
    "section": "",
    "text": "If you’re interested in studying how voice varies across demographics and vocal health, the PVQD is a great starting point. Not only does the dataset contain ~2hrs of audio from vastly different speakers, the data also comes with demographic information about the speakers as well. Let’s visualize that now.\n\n\nCode\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nplt.rcdefaults() # Default\n\ndemo_df = pd.read_csv(\"../../data/pvqd/pvqd_demographics.csv\")\ndemo_df.head(5)\n\n\n\n\n\n\n\n\n\nParticipant ID\nGender\nAge\nDiagnosis\n\n\n\n\n0\nBL01\nM\n46\nNaN\n\n\n1\nBL02\nF\n76\nNaN\n\n\n2\nBL03\nF\n88\nNaN\n\n\n3\nBL04\nF\n42\nNaN\n\n\n4\nBL05\nF\n75\nNaN\n\n\n\n\n\n\n\nWe see that the PVQD comes with three pieces of demographic information: the participants’ Gender, Age, Diagnosis. Frustratingly as someone interested in studying transgender and gender-diverse voices, there aren’t that many datasets out there that contain more inclusive labels of gender. Gender, in the vast majority of datasets, is listed as a binary “F” or “M”. In addition to binary labels of gender, from my personal experience, most of publicly available speech datasets do not contain non-cisgender speakers. For the construction of machine learning models that can provide feedback on gender affirming voice training, this is a huge limitation. Machine learning methods often fail to generalize to unseen data, especially when that data is “out of distribution”.\nAlthough we won’t be able to get a complete map of what voice is capable of, we can start to get a rough one. The nice thing about the PVQD is that it does provide us with voices that do exhibit certain qualities we might want to avoid during voice training, such as breathiness and strain. Let’s load in that data while we’re talking about it:\n\n\nCode\npq_train = pd.read_csv(\"../../data/pvqd/train_test_split/y_train.csv\", index_col=0)\npq_train.head(5)\n\n\n\n\n\n\n\n\n\nFile\nBreathiness\nLoudness\nPitch\nRoughness\nStrain\n\n\n\n\n0\nLA7005\n7.000000\n7.333333\n7.000000\n8.500000\n8.000000\n\n\n1\nPT116\n31.833333\n12.333333\n6.000000\n29.500000\n7.333333\n\n\n2\nPT034\n43.166667\n26.666667\n61.166667\n34.000000\n30.333333\n\n\n3\nSJ6006\n4.375000\n5.125000\n0.250000\n3.750000\n6.875000\n\n\n4\nPT005\n5.500000\n7.000000\n12.000000\n3.833333\n4.500000\n\n\n\n\n\n\n\nAs we said before, the CAPE-V measures perceptual qualities on a 1-100 scale. Since these values are the average of six different raitngs, we get all those decimal places. It’s nice to look at the data like that, to make sure it’s there, but we’re still a bit away from actually learning anything about the data. I’m brushing this part under the rug (see the workshop if you’re curious!), but I’m going to clean up the data and combine the two dataframes so we can start drawing some connections.\n\n\nCode\n### Fix up the demo_df first\n\n## Fix Gender\ncor_gender = {\n    \"f\": \"F\",\n    \"m\": \"M\",\n    \"female\": \"F\",\n    \"male\": \"M\"\n}\n\ndemo_df[\"Gender\"] = demo_df[\"Gender\"].str.lower().map(cor_gender)\n\n## Make Binary Value for Diagnosis\n# Create a function to apply to the column\ndef process_diagnosis(diagnosis):\n    if pd.isnull(diagnosis):\n        return np.nan\n    if diagnosis == \"N\":\n        return \"N\"\n    else:\n        return \"Y\"\n\ndemo_df[\"Diagnosis \"] = demo_df[\"Diagnosis \"].map(process_diagnosis)\n\n## We can't visualize nan data, so let's not consider those rows\n# ~ is a way to invert a numpy array/pandas series of boolean values. A handy trick\ndiagnosis_df = demo_df[~pd.isnull(demo_df[\"Diagnosis \"])]\n\n# Rename column and remote white space\ndiagnosis_df = diagnosis_df.rename(columns={\"Participant ID \": \"File\"})\ndiagnosis_df[\"File\"] = diagnosis_df[\"File\"].str.upper().str.strip()\n\n## Combine the Data\n\n# Merge the two dataframes using a left join\nmatched_df = pq_train.merge(diagnosis_df, how=\"left\", on=\"File\")\n\nmatched_df = matched_df[~pd.isnull(matched_df[\"Gender\"])]\n\nprint(\"Number of NaN Values: %s\" % len(matched_df[pd.isnull(matched_df[\"Gender\"])]))\n\nmatched_df.head()\n\n\nNumber of NaN Values: 0\n\n\n\n\n\n\n\n\n\nFile\nBreathiness\nLoudness\nPitch\nRoughness\nStrain\nGender\nAge\nDiagnosis\n\n\n\n\n0\nLA7005\n7.000000\n7.333333\n7.000000\n8.500000\n8.000000\nF\n52.0\nY\n\n\n1\nPT116\n31.833333\n12.333333\n6.000000\n29.500000\n7.333333\nF\n81.0\nY\n\n\n2\nPT034\n43.166667\n26.666667\n61.166667\n34.000000\n30.333333\nF\n80.0\nY\n\n\n3\nSJ6006\n4.375000\n5.125000\n0.250000\n3.750000\n6.875000\nF\n17.0\nN\n\n\n4\nPT005\n5.500000\n7.000000\n12.000000\n3.833333\n4.500000\nF\n58.0\nY\n\n\n\n\n\n\n\nCool! We have our combined dataset that has all the information in one place."
  },
  {
    "objectID": "posts/explore_pvqd/index.html#visualizing-the-pvqd",
    "href": "posts/explore_pvqd/index.html#visualizing-the-pvqd",
    "title": "Voice Research #1: Exploring the Perceptual Voice Qualities Database with Pandas and Seaborn",
    "section": "",
    "text": "Let’s start doing our explorations! The first thing we should figure out is what the age and gender makeup of the dataset looks like.\n\n\nCode\ngender_breakdown = diagnosis_df[[\"Gender\", \"Age\"]].groupby(\"Gender\").agg([\"mean\", \"count\"]).reset_index()\n\nsns.histplot(data=diagnosis_df, x=\"Age\", hue=\"Gender\")\nplt.show()\n\ngender_breakdown\n\n\n\n\n\n\n\n\n\n\n\n\nGender\nAge\n\n\n\n\nmean\ncount\n\n\n\n\n0\nF\n43.861878\n181\n\n\n1\nM\n50.020833\n96\n\n\n\n\n\n\n\nSeems like there’s about twice as many women in the dataset than men, with many of the women being younger on average.\nWhat about the age and diagnosis breakdown?\n\n\nCode\nsns.histplot(data=diagnosis_df, x=\"Age\", hue=\"Diagnosis \")\nplt.show()\n\n\n\n\n\nWhile there are quite a few young people with diagnosis, we see that healthy older individuals are underrepresented in the dataset, and the majority of those with diagnoses skew older.\nFrom this point on, it’s important to note that I’m only dealing with the training set to avoid biasing the results we find. It is okay to compute statistics about the demographics over the entire dataset, but, since we are hoping to build models that learn the perceptual qualities, performing data exploration with them in the data could possibly bias our findings. To make sure we have a proper test set to evaluate our findings on, we’ll conduct our exploration on the training data."
  }
]