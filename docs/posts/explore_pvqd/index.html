<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Robin">
<meta name="dcterms.date" content="2023-11-04">

<title>Robin/e Netzorg - Voice Research #1: Exploring the Perceptual Voice Qualities Database with Pandas and Seaborn</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Robin/e Netzorg</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../posts.html" rel="" target="">
 <span class="menu-text">Tutorials, Demos, and Random, Random Musings</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/robbizorg" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/RNetzorg" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://scholar.google.com/citations?user=2L_8ynAAAAAJ&amp;hl=en" rel="" target=""><i class="bi bi-mortarboard" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Voice Research #1: Exploring the Perceptual Voice Qualities Database with Pandas and Seaborn</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">perceptual qualities</div>
                <div class="quarto-category">voice research</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Robin </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 4, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#wee-woo-this-is-a-work-in-progress" id="toc-wee-woo-this-is-a-work-in-progress" class="nav-link active" data-scroll-target="#wee-woo-this-is-a-work-in-progress">WEE-WOO: This is a work in progress</a>
  <ul class="collapse">
  <li><a href="#why-use-data-science-and-machine-learning-to-study-voice" id="toc-why-use-data-science-and-machine-learning-to-study-voice" class="nav-link" data-scroll-target="#why-use-data-science-and-machine-learning-to-study-voice">Why Use Data Science and Machine Learning to Study Voice?</a></li>
  <li><a href="#what-are-perceptual-voice-qualities-and-the-pvqd" id="toc-what-are-perceptual-voice-qualities-and-the-pvqd" class="nav-link" data-scroll-target="#what-are-perceptual-voice-qualities-and-the-pvqd">What are Perceptual Voice Qualities and the PVQD?</a>
  <ul class="collapse">
  <li><a href="#perceptual-qualities-examples" id="toc-perceptual-qualities-examples" class="nav-link" data-scroll-target="#perceptual-qualities-examples">Perceptual Qualities Examples</a></li>
  </ul></li>
  <li><a href="#what-are-pandas-and-seaborn" id="toc-what-are-pandas-and-seaborn" class="nav-link" data-scroll-target="#what-are-pandas-and-seaborn">What are Pandas and Seaborn?</a></li>
  <li><a href="#preprocessing-the-pvqd" id="toc-preprocessing-the-pvqd" class="nav-link" data-scroll-target="#preprocessing-the-pvqd">Preprocessing the PVQD</a></li>
  <li><a href="#visualizing-the-pvqd" id="toc-visualizing-the-pvqd" class="nav-link" data-scroll-target="#visualizing-the-pvqd">Visualizing the PVQD</a></li>
  <li><a href="#what-did-we-learn" id="toc-what-did-we-learn" class="nav-link" data-scroll-target="#what-did-we-learn">What did we learn?</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="wee-woo-this-is-a-work-in-progress" class="level1">
<h1>WEE-WOO: This is a work in progress</h1>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="thumbnail.webp" width="800" height="300" class="figure-img"></p>
<figcaption class="figure-caption">Another day, another tutorial</figcaption>
</figure>
</div>
<p>Welcome to a blog post about exploring the <span class="no-underline"><a href="https://voicefoundation.org/health-science/videos-education/pvqd/">Perceptual Voice Qualities Database (PVQD)</a></span>. This is based off of a ML + Speech workshop I held in the Berkeley Speech Group in Fall ’23. <span class="no-underline"><a href="https://github.com/Berkeley-Speech-Group/audio_ml_workshop_2023">That workshop and the workbooks are available online</a></span> if you want to work with the code yourself! If you’re interested in Deep Learning, there’s also some cool stuff in there about working with HuBERT representations of speech data too! The workshop doesn’t assume any knowledge of Pandas, Machine Learning, or Deep Learning, with the focus is more on getting your hands dirty with the tools vs.&nbsp;understanding 100% of what you’re doing.</p>
<p>That said, if you want to learn more about the tools, the repo contains a list of resources for learning more.</p>
<p>Anyways, if I’m linking to that repo, you might be wondering, why write a blog post about it? First, who doesn’t love a bit of redundancy? Second, not everyone is going to want to actually work with the code themselves. I want to communicate and share the stuff I’ve been working on, and generally share the thought processes I have when trying to work with Speech data. This is to get feedback on my work from folks who might not know a lot about data science and machine learning. This is also to serve as a type of onboarding and explanation tool for those interested in conducting voice research with publicly available datasets. Finally, I really, really need just say what I do in plain english!</p>
<p>And the plain English explanation is simple. Or, well, at least short. I use data science and machine learning to study voice and voice modification. I’m particularly interested in possible applications to transgender and gender-diverse voice training.</p>
<section id="why-use-data-science-and-machine-learning-to-study-voice" class="level2">
<h2 class="anchored" data-anchor-id="why-use-data-science-and-machine-learning-to-study-voice">Why Use Data Science and Machine Learning to Study Voice?</h2>
<p>This question deserves an entire post of its own, not to mention a long discussion on the state of research in voice and voice training more generally. Still, any good tutorial requires a motivation, and the oversimplified version is this: When it comes to modifying a voice, both artificially via speech processing and physically via voice training, the current research is lacking. In speech processing, high-level modification of a particular voice is feasible, such as automatically turning a specific masculine voice into a specific feminine voice, but trying to perform lower-level modification of qualities like breathiness, strain, or resonance is either unclear or requires specialized expert knowledge. In the world of voice and voice training, research into Gender-Affirming Voice Care (GAVC) is only really starting to gain traction in Speech Language Pathology, and many of the pedagogies people pursue from online trans voice communities have not been validated experimentally or quantitatively in a formal setting. From an institutional, formal perspective, the effectiveness of behavioral voice modification, and particular approaches and pedagogies, is largely unknown.</p>
<p>There’s perspectives waiting to be studied, methods to be discovered, and misconceptions to be debunked. The collection and analysis of data, combined with the modeling potential of machine learning, can help in those pursuits. How? That’s a topic for a post of its own. For the time being, let’s go ahead and study some perceptual voice qualities.</p>
</section>
<section id="what-are-perceptual-voice-qualities-and-the-pvqd" class="level2">
<h2 class="anchored" data-anchor-id="what-are-perceptual-voice-qualities-and-the-pvqd">What are Perceptual Voice Qualities and the PVQD?</h2>
<section id="perceptual-qualities-examples" class="level3">
<h3 class="anchored" data-anchor-id="perceptual-qualities-examples">Perceptual Qualities Examples</h3>
<p>Here’s a list of examples of the perceptual qualities.</p>
</section>
</section>
<section id="what-are-pandas-and-seaborn" class="level2">
<h2 class="anchored" data-anchor-id="what-are-pandas-and-seaborn">What are Pandas and Seaborn?</h2>
</section>
<section id="preprocessing-the-pvqd" class="level2">
<h2 class="anchored" data-anchor-id="preprocessing-the-pvqd">Preprocessing the PVQD</h2>
<p>If you’re interested in studying how voice varies across demographics and vocal health, the PVQD is a great starting point. Not only does the dataset contain ~2hrs of audio from vastly different speakers, the data also comes with demographic information about the speakers as well. Let’s visualize that now.</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>plt.rcdefaults() <span class="co"># Default</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>demo_df <span class="op">=</span> pd.read_csv(<span class="st">"../../data/pvqd/pvqd_demographics.csv"</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>demo_df.head(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="17">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Participant ID</th>
<th data-quarto-table-cell-role="th">Gender</th>
<th data-quarto-table-cell-role="th">Age</th>
<th data-quarto-table-cell-role="th">Diagnosis</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>BL01</td>
<td>M</td>
<td>46</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>BL02</td>
<td>F</td>
<td>76</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>BL03</td>
<td>F</td>
<td>88</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>BL04</td>
<td>F</td>
<td>42</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>BL05</td>
<td>F</td>
<td>75</td>
<td>NaN</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>We see that the PVQD comes with three pieces of demographic information: the participants’ Gender, Age, Diagnosis. Frustratingly as someone interested in studying transgender and gender-diverse voices, there aren’t that many datasets out there that contain more inclusive labels of gender. Gender, in the vast majority of datasets, is listed as a binary “F” or “M”. In addition to binary labels of gender, from my personal experience, most of publicly available speech datasets do not contain non-cisgender speakers. For the construction of machine learning models that can provide feedback on gender affirming voice training, this is a huge limitation. Machine learning methods often fail to generalize to unseen data, especially when that data is “out of distribution”.</p>
<p>Although we won’t be able to get a complete map of what voice is capable of, we can start to get a rough one. The nice thing about the PVQD is that it does provide us with voices that do exhibit certain qualities we might want to avoid during voice training, such as breathiness and strain. Let’s load in that data while we’re talking about it:</p>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>pq_train <span class="op">=</span> pd.read_csv(<span class="st">"../../data/pvqd/train_test_split/y_train.csv"</span>, index_col<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>pq_train.head(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="18">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">File</th>
<th data-quarto-table-cell-role="th">Breathiness</th>
<th data-quarto-table-cell-role="th">Loudness</th>
<th data-quarto-table-cell-role="th">Pitch</th>
<th data-quarto-table-cell-role="th">Roughness</th>
<th data-quarto-table-cell-role="th">Strain</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>LA7005</td>
<td>7.000000</td>
<td>7.333333</td>
<td>7.000000</td>
<td>8.500000</td>
<td>8.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>PT116</td>
<td>31.833333</td>
<td>12.333333</td>
<td>6.000000</td>
<td>29.500000</td>
<td>7.333333</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>PT034</td>
<td>43.166667</td>
<td>26.666667</td>
<td>61.166667</td>
<td>34.000000</td>
<td>30.333333</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>SJ6006</td>
<td>4.375000</td>
<td>5.125000</td>
<td>0.250000</td>
<td>3.750000</td>
<td>6.875000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>PT005</td>
<td>5.500000</td>
<td>7.000000</td>
<td>12.000000</td>
<td>3.833333</td>
<td>4.500000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>As we said before, the CAPE-V measures perceptual qualities on a 1-100 scale. Since these values are the average of six different raitngs, we get all those decimal places. It’s nice to look at the data like that, to make sure it’s there, but we’re still a bit away from actually learning anything about the data. I’m brushing this part under the rug (see the workshop if you’re curious!), but I’m going to clean up the data and combine the two dataframes so we can start drawing some connections.</p>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">### Fix up the demo_df first</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">## Fix Gender</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>cor_gender <span class="op">=</span> {</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"f"</span>: <span class="st">"F"</span>,</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"m"</span>: <span class="st">"M"</span>,</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"female"</span>: <span class="st">"F"</span>,</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"male"</span>: <span class="st">"M"</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>demo_df[<span class="st">"Gender"</span>] <span class="op">=</span> demo_df[<span class="st">"Gender"</span>].<span class="bu">str</span>.lower().<span class="bu">map</span>(cor_gender)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co">## Make Binary Value for Diagnosis</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a function to apply to the column</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> process_diagnosis(diagnosis):</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pd.isnull(diagnosis):</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.nan</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> diagnosis <span class="op">==</span> <span class="st">"N"</span>:</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"N"</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"Y"</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>demo_df[<span class="st">"Diagnosis "</span>] <span class="op">=</span> demo_df[<span class="st">"Diagnosis "</span>].<span class="bu">map</span>(process_diagnosis)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a><span class="co">## We can't visualize nan data, so let's not consider those rows</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a><span class="co"># ~ is a way to invert a numpy array/pandas series of boolean values. A handy trick</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>diagnosis_df <span class="op">=</span> demo_df[<span class="op">~</span>pd.isnull(demo_df[<span class="st">"Diagnosis "</span>])]</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Rename column and remote white space</span></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>diagnosis_df <span class="op">=</span> diagnosis_df.rename(columns<span class="op">=</span>{<span class="st">"Participant ID "</span>: <span class="st">"File"</span>})</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>diagnosis_df[<span class="st">"File"</span>] <span class="op">=</span> diagnosis_df[<span class="st">"File"</span>].<span class="bu">str</span>.upper().<span class="bu">str</span>.strip()</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a><span class="co">## Combine the Data</span></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge the two dataframes using a left join</span></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>matched_df <span class="op">=</span> pq_train.merge(diagnosis_df, how<span class="op">=</span><span class="st">"left"</span>, on<span class="op">=</span><span class="st">"File"</span>)</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>matched_df <span class="op">=</span> matched_df[<span class="op">~</span>pd.isnull(matched_df[<span class="st">"Gender"</span>])]</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of NaN Values: </span><span class="sc">%s</span><span class="st">"</span> <span class="op">%</span> <span class="bu">len</span>(matched_df[pd.isnull(matched_df[<span class="st">"Gender"</span>])]))</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>matched_df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Number of NaN Values: 0</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="19">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">File</th>
<th data-quarto-table-cell-role="th">Breathiness</th>
<th data-quarto-table-cell-role="th">Loudness</th>
<th data-quarto-table-cell-role="th">Pitch</th>
<th data-quarto-table-cell-role="th">Roughness</th>
<th data-quarto-table-cell-role="th">Strain</th>
<th data-quarto-table-cell-role="th">Gender</th>
<th data-quarto-table-cell-role="th">Age</th>
<th data-quarto-table-cell-role="th">Diagnosis</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>LA7005</td>
<td>7.000000</td>
<td>7.333333</td>
<td>7.000000</td>
<td>8.500000</td>
<td>8.000000</td>
<td>F</td>
<td>52.0</td>
<td>Y</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>PT116</td>
<td>31.833333</td>
<td>12.333333</td>
<td>6.000000</td>
<td>29.500000</td>
<td>7.333333</td>
<td>F</td>
<td>81.0</td>
<td>Y</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>PT034</td>
<td>43.166667</td>
<td>26.666667</td>
<td>61.166667</td>
<td>34.000000</td>
<td>30.333333</td>
<td>F</td>
<td>80.0</td>
<td>Y</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>SJ6006</td>
<td>4.375000</td>
<td>5.125000</td>
<td>0.250000</td>
<td>3.750000</td>
<td>6.875000</td>
<td>F</td>
<td>17.0</td>
<td>N</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>PT005</td>
<td>5.500000</td>
<td>7.000000</td>
<td>12.000000</td>
<td>3.833333</td>
<td>4.500000</td>
<td>F</td>
<td>58.0</td>
<td>Y</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Cool! We have our combined dataset that has all the information in one place.</p>
</section>
<section id="visualizing-the-pvqd" class="level2">
<h2 class="anchored" data-anchor-id="visualizing-the-pvqd">Visualizing the PVQD</h2>
<p>Let’s start doing our explorations! The first thing we should figure out is what the age and gender makeup of the dataset looks like.</p>
<div class="cell" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>gender_breakdown <span class="op">=</span> diagnosis_df[[<span class="st">"Gender"</span>, <span class="st">"Age"</span>]].groupby(<span class="st">"Gender"</span>).agg([<span class="st">"mean"</span>, <span class="st">"count"</span>]).reset_index()</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>sns.histplot(data<span class="op">=</span>diagnosis_df, x<span class="op">=</span><span class="st">"Age"</span>, hue<span class="op">=</span><span class="st">"Gender"</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>gender_breakdown</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-5-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display" data-execution_count="20">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Gender</th>
<th colspan="2" data-quarto-table-cell-role="th" data-halign="left">Age</th>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">count</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>F</td>
<td>43.861878</td>
<td>181</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>M</td>
<td>50.020833</td>
<td>96</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Seems like there’s about twice as many women in the dataset than men, with many of the women being younger on average.</p>
<p>What about the age and diagnosis breakdown?</p>
<div class="cell" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>sns.histplot(data<span class="op">=</span>diagnosis_df, x<span class="op">=</span><span class="st">"Age"</span>, hue<span class="op">=</span><span class="st">"Diagnosis "</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-6-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>While there are quite a few young people with diagnosis, we see that healthy older individuals are underrepresented in the dataset, and the majority of those with diagnoses skew older.</p>
<p>From this point on, it’s important to note that I’m only dealing with the <a href="https://machinelearningmastery.com/train-test-split-for-evaluating-machine-learning-algorithms/">training set</a> to avoid biasing the results we find. It is okay to compute statistics about the demographics over the entire dataset, but, since we are hoping to build models that learn the perceptual qualities, performing data exploration with them in the data could possibly bias our findings. To make sure we have a proper test set to evaluate our findings on, we’ll conduct our exploration on the training data.</p>
<p>Let’s go ahead and visualize the relationship between vocal health and the CAPE-V ratings as reported in the PVQD. First, we’ll compute some aggregate statistics between speakers with diagnoses and those without.</p>
<div class="cell" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make sure that the diagnosis_df's File column matches that of pq_train</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>diagnosis_df[<span class="st">"File"</span>] <span class="op">=</span> diagnosis_df[<span class="st">"File"</span>].<span class="bu">str</span>.upper().<span class="bu">str</span>.strip()</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge the two dataframes using a left join</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>matched_df <span class="op">=</span> pq_train.merge(diagnosis_df, how<span class="op">=</span><span class="st">"left"</span>, on<span class="op">=</span><span class="st">"File"</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter out the NaN Examples and Run a Quick Check</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>matched_df <span class="op">=</span> matched_df[<span class="op">~</span>pd.isnull(matched_df[<span class="st">"Gender"</span>])]</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> <span class="bu">len</span>(matched_df[pd.isnull(matched_df[<span class="st">"Gender"</span>])]) <span class="op">==</span> <span class="dv">0</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Here's a df of the PQs and the diagnosis value</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>pq_and_diagnosis_df <span class="op">=</span> matched_df[[<span class="st">"Diagnosis "</span>, <span class="st">"Breathiness"</span>, <span class="st">"Loudness"</span>, <span class="st">"Pitch"</span>, <span class="st">"Roughness"</span>, <span class="st">"Strain"</span>]]</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">TODO</span><span class="co">: Calculate the Average, Median, and Max PQ per diagnosis</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>pq_and_diagnosis_df.groupby(<span class="st">"Diagnosis "</span>).agg([<span class="st">"mean"</span>, <span class="st">"median"</span>, <span class="st">"max"</span>]).<span class="bu">round</span>(<span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="22">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th colspan="3" data-quarto-table-cell-role="th" data-halign="left">Breathiness</th>
<th colspan="3" data-quarto-table-cell-role="th" data-halign="left">Loudness</th>
<th colspan="3" data-quarto-table-cell-role="th" data-halign="left">Pitch</th>
<th colspan="3" data-quarto-table-cell-role="th" data-halign="left">Roughness</th>
<th colspan="3" data-quarto-table-cell-role="th" data-halign="left">Strain</th>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">median</th>
<th data-quarto-table-cell-role="th">max</th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">median</th>
<th data-quarto-table-cell-role="th">max</th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">median</th>
<th data-quarto-table-cell-role="th">max</th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">median</th>
<th data-quarto-table-cell-role="th">max</th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">median</th>
<th data-quarto-table-cell-role="th">max</th>
</tr>
<tr class="header">
<th data-quarto-table-cell-role="th">Diagnosis</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">N</td>
<td>8.81</td>
<td>5.50</td>
<td>38.0</td>
<td>4.24</td>
<td>2.94</td>
<td>21.83</td>
<td>4.69</td>
<td>2.33</td>
<td>20.83</td>
<td>11.76</td>
<td>10.17</td>
<td>44.62</td>
<td>9.88</td>
<td>8.21</td>
<td>32.50</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Y</td>
<td>24.06</td>
<td>16.17</td>
<td>99.5</td>
<td>24.49</td>
<td>14.67</td>
<td>99.17</td>
<td>22.02</td>
<td>12.17</td>
<td>99.17</td>
<td>25.78</td>
<td>21.50</td>
<td>84.83</td>
<td>26.20</td>
<td>18.17</td>
<td>96.83</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>This isn’t the prettiest table, but it gets the point across. We see the sort of trends we’d expect. Comparing means and medians across perceptual qualities, we note that voices with diagnoses have higher ratings than those without, with the maximum values for diagnosed speakers across all PQs except roughness being close to 100. If you’re familiar with statistics, you might be wondering if these differences are statistically significant. I leave it as an exercise to the reader to test this question in the associated workbooks! For this exploration, I’m happy enough to note that the difference we’d expect to see is indeed there. The max for non-diagnosed voices is lower, but can vary greatly from PQ to PQ. Breathiness, for example, has a maximum value of 38.0 while loudness has a maximum value of 21.83.</p>
<p>Let’s visualize the distributions to understand if these are flukes or a larger part of the distribution. Orange represents speakers without a diagnosis.</p>
<div class="cell" data-execution_count="7">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Same df as before, but going to include the File to make it clearer</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>pq_and_diagnosis_df <span class="op">=</span> matched_df[[<span class="st">"File"</span>, <span class="st">"Age"</span>, <span class="st">"Diagnosis "</span>, <span class="st">"Breathiness"</span>, <span class="st">"Loudness"</span>, <span class="st">"Pitch"</span>, <span class="st">"Roughness"</span>, <span class="st">"Strain"</span>]]</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a Long DataFrame</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>long_df <span class="op">=</span> pd.melt(pq_and_diagnosis_df, id_vars <span class="op">=</span> [<span class="st">"File"</span>, <span class="st">"Age"</span>, <span class="st">"Diagnosis "</span>], value_vars<span class="op">=</span>[<span class="st">"Breathiness"</span>, <span class="st">"Loudness"</span>, <span class="st">"Pitch"</span>, <span class="st">"Roughness"</span>, <span class="st">"Strain"</span>], var_name <span class="op">=</span> <span class="st">"PQ"</span>, value_name <span class="op">=</span> <span class="st">"Value"</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a FacetGrid to plot a lot of things all at once</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> sns.FacetGrid(data<span class="op">=</span>long_df, col <span class="op">=</span> <span class="st">"PQ"</span>, hue <span class="op">=</span> <span class="st">"Diagnosis "</span>)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>g.<span class="bu">map</span>(sns.histplot, <span class="st">"Value"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-8-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Cool! It seems like it kind of is a fluke, with the highest value being around 25-30 for many of the non-diagnosed voices. It would be good to compute different quartiles or a CDF right about now to more rigorously confirm this, but also going to leave this to the curious reader :D</p>
<p>We still haven’t looked at age and these perceptual qualities yet. Let’s go ahead and combine the above plots with an age dimension. Orange again represents voices without a diagnosis.</p>
<div class="cell" data-execution_count="8">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a FacetGrid to plot a lot of things all at once</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> sns.FacetGrid(data<span class="op">=</span>long_df, col <span class="op">=</span> <span class="st">"PQ"</span>, hue <span class="op">=</span> <span class="st">"Diagnosis "</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>g.<span class="bu">map</span>(sns.scatterplot, <span class="st">"Age"</span>, <span class="st">"Value"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-9-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>It’s interesting to note that across PQs there tends to be a slight correlation between age and the perceptual quality, with a few of the PQs, like strain, not having any examples of folks who are younger than 30 with highly strained voices. Some PQs do have examples for younger individuals, but even then it’s not many.</p>
</section>
<section id="what-did-we-learn" class="level2">
<h2 class="anchored" data-anchor-id="what-did-we-learn">What did we learn?</h2>
<p>There’s one main takeaway we walk away with by performing this data exploration: we learn about the data distributions and correlations present in the PVQD data (under our particular set of processing choices). This can tell us about the limits of various modeling approaches we can expect, or failures of generation. For example, if we were to train a model that sought to return a 1-100 value for strain from an individual’s voice, if that individual is young and has a strained voice, our model might not be able to generalize to this new datapoint–possibly returning that the voice is less strained than it actually is. In this case, the model would have too strongly associated strain with age-specific vocal features, instead of learning what strain is across age groups. This visualization and exploration helps point out possible failures of modeling we could expect.</p>
<p>Another takeaway from this exploration is how SLPs label audio data ccording to the CAPE-V protocol. If we wished to incorporate different types of data, or perhaps even learn how to provide CAPE-V ratings ourselves, it’s incredibly important to know the difference between voices with high and low values of a particular perceptual quality. Given that this dataset is primarily concerned with patients with voice disorders, knowing the values that healthy or “typical” voices might have lets us know what PQ values healthy voices in other datasets should have. Generalization is a huge issue for machine learning and deep learning models. Having knowledge about how experts use the CAPE-V protocol across voices facilitates the future collection of more data to mitigate the generalization issue.</p>
<p>In the next post, we’re going to try to and actually model some of these perceptual qualities. Let’s see if we can do as the experts do!</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>